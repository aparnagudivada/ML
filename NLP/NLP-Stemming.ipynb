{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d64145-8819-48cc-b7e1-9bc058675e72",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50177b3c-0969-437d-a0b7-13d9e5b98f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comment of product is a positive or negative review\n",
    "## Reviews ----->eating, eat, eaten [going, gone, goes]-->go\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf1837-86aa-41c9-a1ab-fd4b1e5912e5",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08fdf7b-5e35-4c69-8898-6de805c6b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d479e13-727a-40e6-b217-4944b052db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503570b1-8dce-4cfe-b3d0-158eb9ec9c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalized--->final\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i+\"--->\"+stemming.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c7d032-d185-4790-969d-4690815c905f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbfb1f0a-fdf9-4e80-b0be-d4998d26d5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21788c-bd66-4029-b429-f654ea13e983",
   "metadata": {},
   "source": [
    "## RegexpStemmer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abccaa8-6774-4d89-bd8e-50b13fd9f599",
   "metadata": {},
   "source": [
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23d72bf-297e-4be8-aead-6db2fc753cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf5ecab-fe01-44d0-8bc7-e55a09439d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0699fb1b-dbef-4fc1-afb2-4da9ca8e6a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64447312-f471-403f-8eab-286da35b1231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc758f-3712-420a-b23b-cee107b43dd0",
   "metadata": {},
   "source": [
    "## Snowball Stemmer\n",
    "It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea05cdc-28a4-48ab-9e4b-4835f7d4f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "413c4ae6-5126-4381-b371-84e84cc5f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballsstemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59ad5279-fafe-47ac-9422-9f3ccf01f257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalized--->final\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i+\"--->\"+snowballsstemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7b34447-9275-4e87-9d97-b4ec6e41d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'), stemming.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d689723-2fe6-4b3a-9741-2bde5e1927bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55e79866-20c7-4409-bb69-578b819b0a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9e37269-372a-4837-8315-539a7b11eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a950b-6f08-4c95-94e4-6de76099d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
